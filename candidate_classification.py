import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
import pandas as pd
import numpy as np
import joblib
import os
import pickle

def show_candidate_overview():
    """Hi·ªÉn th·ªã t·ªïng quan Candidate Classification"""
    st.markdown("#### üìä T·ªïng quan ph√¢n b·ªë d·ªØ li·ªáu v√† k·∫øt qu·∫£ m√¥ h√¨nh")
    
    # Row 1: Company Type v√† Company Industry
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("##### üè¢ Ph√¢n ph·ªëi Company Type")
        company_types = ['IT Product', 'IT Outsourcing', 'IT Service and IT Consulting', 'Non-IT']
        company_type_values = [295, 86, 68, 29]
        
        fig = px.pie(
            values=company_type_values, 
            names=company_types,
            color_discrete_sequence=['#3498db', '#e74c3c', '#f39c12', '#95a5a6']
        )
        fig.update_layout(
            title="Ph√¢n ph·ªëi theo lo·∫°i c√¥ng ty",
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color='white',
            height=350,
            showlegend=True
        )
        fig.update_traces(textposition='inside', textinfo='percent+label')
        st.plotly_chart(fig, use_container_width=True)
        
        # Hi·ªÉn th·ªã stats
        st.markdown("""
        <div style="background: #34495e; padding: 1rem; border-radius: 5px; margin-top: 0.5rem;">
            <p style="color: white; margin: 0;"><strong>Total:</strong> 478 c√¥ng ty</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("##### üè≠ Ph√¢n ph·ªëi Company Industry")
        industries = ['Software Products and Web Services', 'IT Services and IT Consulting', 
                     'Software Development Outsourcing', 'Financial Services', 'E-commerce']
        industry_values = [107, 104, 66, 30, 23]
        
        fig = go.Figure(data=[go.Bar(
            x=industries, 
            y=industry_values,
            marker_color=['#1abc9c', '#3498db', '#9b59b6', '#e74c3c', '#f39c12']
        )])
        
        fig.update_layout(
            title="Top 5 ng√†nh c√¥ng nghi·ªáp",
            xaxis_title="Ng√†nh ngh·ªÅ",
            yaxis_title="S·ªë l∆∞·ª£ng",
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color='white',
            xaxis_tickangle=-45,
            height=350,
            margin=dict(b=100)
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Hi·ªÉn th·ªã stats
        st.markdown("""
        <div style="background: #34495e; padding: 1rem; border-radius: 5px; margin-top: 0.5rem;">
            <p style="color: white; margin: 0;"><strong>Top 5 ng√†nh ngh·ªÅ h√†ng ƒë·∫ßu</strong></p>
        </div>
        """, unsafe_allow_html=True)
    
    # Row 2: Company Size v√† Overtime Policy
    col3, col4 = st.columns(2)
    
    with col3:
        st.markdown("##### üë• Ph√¢n ph·ªëi Company Size")
        company_sizes = ['1-50 employees', '51-150 employees', '1000+ employees', 
                        '151-300 employees', '301-500 employees']
        size_values = [178, 138, 54, 51, 33]
        
        fig = go.Figure(data=[go.Bar(
            y=company_sizes, 
            x=size_values, 
            orientation='h',
            marker_color=['#2ecc71', '#3498db', '#9b59b6', '#e67e22', '#e74c3c']
        )])
        
        fig.update_layout(
            title="Ph√¢n ph·ªëi theo quy m√¥ c√¥ng ty",
            xaxis_title="S·ªë l∆∞·ª£ng",
            yaxis_title="Quy m√¥ nh√¢n vi√™n",
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color='white',
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col4:
        st.markdown("##### ‚è∞ Ph√¢n ph·ªëi Overtime Policy")
        ot_policies = ['No OT', 'Extra salary for OT', 'Extra days off for OT', 'OT included in base salary']
        ot_values = [389, 52, 5, 1]
        
        fig = go.Figure(data=[go.Bar(
            x=ot_policies, 
            y=ot_values,
            marker_color=['#2ecc71', '#3498db', '#f39c12', '#e74c3c']
        )])
        
        fig.update_layout(
            title="Ch√≠nh s√°ch l√†m th√™m gi·ªù",
            xaxis_title="Ch√≠nh s√°ch OT",
            yaxis_title="S·ªë l∆∞·ª£ng",
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color='white',
            xaxis_tickangle=-45,
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Row 3: Label Distribution v√† Text Statistics
    st.markdown("---")
    col5, col6 = st.columns(2)
    
    with col5:
        st.markdown("##### üéØ Ph√¢n ph·ªëi nh√£n Recommend")
        
        labels = ['Not Recommend (0)', 'Recommend (1)']
        label_values = [191, 287]
        label_percentages = [40.0, 60.0]
        
        fig = go.Figure(data=[go.Pie(
            labels=[f'{label}<br>{value} ({pct}%)' for label, value, pct in zip(labels, label_values, label_percentages)],
            values=label_values,
            hole=0.4,
            marker_colors=['#e74c3c', '#2ecc71']
        )])
        
        fig.update_layout(
            title="Ph√¢n b·ªë nh√£n ph√¢n lo·∫°i",
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color='white',
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Summary stats
        st.markdown("""
        <div style="background: #34495e; padding: 1rem; border-radius: 5px; margin-top: 0.5rem;">
            <p style="color: white; margin: 0;"><strong>T·ªïng s·ªë m·∫´u:</strong> 478</p>
            <p style="color: #2ecc71; margin: 0;"><strong>Recommend:</strong> 287 (60.0%)</p>
            <p style="color: #e74c3c; margin: 0;"><strong>Not Recommend:</strong> 191 (40.0%)</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col6:
        st.markdown("##### üìù Th·ªëng k√™ ƒë·ªô d√†i vƒÉn b·∫£n")
        
        # Text statistics s·ª≠ d·ª•ng st.metric tr·ª±c ti·∫øp
        st.metric(
            label="üìä ƒê·ªô d√†i trung b√¨nh",
            value="1,276.95 k√Ω t·ª±"
        )
        st.metric(
            label="üìä ƒê·ªô d√†i median",
            value="1,313.50 k√Ω t·ª±"
        )
        st.metric(
            label="üìä S·ªë t·ª´ trung b√¨nh", 
            value="214.97 t·ª´"
        )
        st.metric(
            label="üìä S·ªë t·ª´ median",
            value="219.00 t·ª´"
        )
    
    # Row 4: Word Cloud Section (di chuy·ªÉn l√™n tr∆∞·ªõc)
    st.markdown("---")
    st.markdown("##### ‚òÅÔ∏è Word Cloud")
    
    # Word Cloud placeholder
    try:
        st.image("images/Word Cloud 1.png", caption="Word Cloud c·ªßa m√¥ t·∫£ c√¥ng vi·ªác", use_container_width=True)
    except:
        st.markdown("""
        <div style="background: #34495e; padding: 2rem; border-radius: 10px; text-align: center; height: 300px; display: flex; flex-direction: column; justify-content: center;">
            <div style="font-size: 3rem; margin-bottom: 1rem;">‚òÅÔ∏è</div>
            <h4 style="color: white;">Word Cloud</h4>
            <p style="color: #bdc3c7;">ƒê·∫∑t file 'Word Cloud.png' trong th∆∞ m·ª•c images/</p>
            <p style="color: #95a5a6; font-size: 0.9rem;">Hi·ªÉn th·ªã c√°c t·ª´ kh√≥a ph·ªï bi·∫øn trong m√¥ t·∫£ c√¥ng vi·ªác</p>
        </div>
        """, unsafe_allow_html=True)

    # Row 5: Model Comparison Section
    st.markdown("---")
    st.markdown("## ü§ñ So s√°nh k·∫øt qu·∫£ c√°c m√¥ h√¨nh Machine Learning")
    
    # T·∫°o data cho b·∫£ng so s√°nh
    model_results = {
        'Model': [
            'SKL_Logistic_Regression', 'SKL_Decision_Tree', 'SKL_Random_Forest',
            'SKL_Gradient_Boosting', 'SKL_KNN', 'SKL_SVM',
            'PySpark_Logistic_Regression', 'PySpark_Decision_Tree', 
            'PySpark_Random_Forest', 'PySpark_GBT'
        ],
        'Accuracy': [0.833333, 0.770833, 0.875, 0.916667, 0.84375, 0.614583, 0.78125, 0.854167, 0.84375, 0.864583],
        'Precision': [0.85, 0.821429, 0.859375, 0.890625, 0.830769, 0.610526, 0.779371, 0.854167, 0.850843, 0.865357],
        'Recall': [0.87931, 0.793103, 0.948276, 0.982759, 0.931034, 1.0, 0.78125, 0.854167, 0.84375, 0.864583],
        'F1-score': [0.864407, 0.807018, 0.901639, 0.934426, 0.878049, 0.75817, 0.778067, 0.854167, 0.838881, 0.864874],
        'ROC-AUC': [0.907441, 0.764973, 0.901543, 0.969601, 0.911298, 0.846416, 0.8598, 0.871824, 0.881579, 0.950544],
        'Framework': ['Scikit-learn', 'Scikit-learn', 'Scikit-learn', 'Scikit-learn', 'Scikit-learn', 'Scikit-learn',
                     'PySpark', 'PySpark', 'PySpark', 'PySpark']
    }
    
    # T·∫°o DataFrame
    df_results = pd.DataFrame(model_results)
    
    # Hi·ªÉn th·ªã b·∫£ng k·∫øt qu·∫£
    st.markdown("##### üìã B·∫£ng so s√°nh k·∫øt qu·∫£ t·∫•t c·∫£ c√°c m√¥ h√¨nh:")
    
    # Format b·∫£ng v·ªõi highlighting cho m√¥ h√¨nh t·ªët nh·∫•t
    def highlight_best_model(row):
        best_f1_idx = df_results['F1-score'].idxmax()
        if row.name == best_f1_idx:
            return ['background-color: #90EE90'] * len(row)
        else:
            return [''] * len(row)
    
    styled_df = df_results.style.apply(highlight_best_model, axis=1).format({
        'Accuracy': '{:.3f}',
        'Precision': '{:.3f}', 
        'Recall': '{:.3f}',
        'F1-score': '{:.3f}',
        'ROC-AUC': '{:.3f}'
    })
    
    st.dataframe(styled_df, use_container_width=True)
    
    # Highlight m√¥ h√¨nh t·ªët nh·∫•t
    best_model_idx = df_results['F1-score'].idxmax()
    best_model_name = df_results.loc[best_model_idx, 'Model']
    best_f1_score = df_results.loc[best_model_idx, 'F1-score']
    
    st.success(f"üèÜ **M√¥ h√¨nh t·ªët nh·∫•t:** {best_model_name} v·ªõi F1-score: {best_f1_score:.3f}")
    
    # Row 5: Visualization so s√°nh m√¥ h√¨nh
    col7, col8 = st.columns(2)
    
    with col7:
        st.markdown("##### üìä So s√°nh F1-Score c√°c m√¥ h√¨nh")
        
        # T·∫°o colors - highlight m√¥ h√¨nh t·ªët nh·∫•t
        colors = ['#FFD700' if model == best_model_name else '#87CEEB' if 'SKL' in model else '#FFA07A' 
                 for model in df_results['Model']]
        
        fig = go.Figure(data=[go.Bar(
            x=df_results['F1-score'],
            y=[model.replace('SKL_', '').replace('PySpark_', 'PS_') for model in df_results['Model']],
            orientation='h',
            marker_color=colors,
            text=[f'{score:.3f}' for score in df_results['F1-score']],
            textposition='auto'
        )])
        
        fig.update_layout(
            title="F1-Score Comparison",
            xaxis_title="F1-Score",
            yaxis_title="Models",
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color='white',
            height=500,
            showlegend=False
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    with col8:
        st.markdown("##### üéØ Framework Performance Comparison")
        
        # So s√°nh theo framework
        framework_avg = df_results.groupby('Framework')[['Accuracy', 'F1-score', 'ROC-AUC']].mean()
        
        metrics = ['Accuracy', 'F1-score', 'ROC-AUC']
        sklearn_values = [framework_avg.loc['Scikit-learn', metric] for metric in metrics]
        pyspark_values = [framework_avg.loc['PySpark', metric] for metric in metrics]
        
        fig = go.Figure()
        
        fig.add_trace(go.Scatterpolar(
            r=sklearn_values,
            theta=metrics,
            fill='toself',
            name='Scikit-learn',
            line_color='#3498db'
        ))
        
        fig.add_trace(go.Scatterpolar(
            r=pyspark_values,
            theta=metrics,
            fill='toself',
            name='PySpark',
            line_color='#e74c3c'
        ))
        
        fig.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 1]
                )),
            showlegend=True,
            title="Framework Performance Radar",
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color='white',
            height=500
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    # Row 6: Best Model Details  
    st.markdown("---")
    st.markdown("## üèÜ Chi ti·∫øt m√¥ h√¨nh t·ªët nh·∫•t: SKL_Gradient_Boosting")
    
    col9, col10 = st.columns(2)
    
    with col9:
        st.markdown("##### üìà Metrics c·ªßa m√¥ h√¨nh t·ªët nh·∫•t")
        
        best_metrics = df_results[df_results['Model'] == best_model_name].iloc[0]
        
        # S·ª≠ d·ª•ng HTML/CSS ƒë·ªÉ hi·ªÉn th·ªã metrics theo h√†ng ngang
        st.markdown(f"""
        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; margin: 1rem 0;">
            <div style="background: #f0f2f6; padding: 1rem; border-radius: 5px; text-align: center;">
                <h4 style="margin: 0; color: #262730;">üéØ Accuracy</h4>
                <h2 style="margin: 0.5rem 0 0 0; color: #262730;">{best_metrics['Accuracy']:.3f}</h2>
            </div>
            <div style="background: #f0f2f6; padding: 1rem; border-radius: 5px; text-align: center;">
                <h4 style="margin: 0; color: #262730;">üîç Precision</h4>
                <h2 style="margin: 0.5rem 0 0 0; color: #262730;">{best_metrics['Precision']:.3f}</h2>
            </div>
        </div>
        
        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; margin: 1rem 0;">
            <div style="background: #f0f2f6; padding: 1rem; border-radius: 5px; text-align: center;">
                <h4 style="margin: 0; color: #262730;">üìä Recall</h4>
                <h2 style="margin: 0.5rem 0 0 0; color: #262730;">{best_metrics['Recall']:.3f}</h2>
            </div>
            <div style="background: #f0f2f6; padding: 1rem; border-radius: 5px; text-align: center;">
                <h4 style="margin: 0; color: #262730;">‚ö° ROC-AUC</h4>
                <h2 style="margin: 0.5rem 0 0 0; color: #262730;">{best_metrics['ROC-AUC']:.3f}</h2>
            </div>
        </div>
        
        <div style="background: linear-gradient(90deg, #FFD700, #FFA500); padding: 1rem; border-radius: 10px; text-align: center; margin: 1rem 0;">
            <h3 style="color: #000; margin: 0;">üèÜ F1-Score: {best_metrics['F1-score']:.3f}</h3>
        </div>
        """, unsafe_allow_html=True)
    
    with col10:
        st.markdown("##### üìä Classification Report")
        
        # Classification Report - ƒë∆°n gi·∫£n h√≥a ƒë·ªÉ tr√°nh l·ªói hi·ªÉn th·ªã
        report_data = [
            ['Not Recommend', '0.97', '0.82', '0.89', '38'],
            ['Recommend', '0.89', '0.98', '0.93', '58'],
            ['Accuracy', '', '', '0.92', '96'],
            ['Macro avg', '0.93', '0.90', '0.91', '96'],
            ['Weighted avg', '0.92', '0.92', '0.92', '96']
        ]
        
        report_df = pd.DataFrame(report_data, columns=['Class', 'Precision', 'Recall', 'F1-score', 'Support'])
        
        # Hi·ªÉn th·ªã b·∫£ng ƒë∆°n gi·∫£n kh√¥ng c√≥ styling ph·ª©c t·∫°p
        st.dataframe(report_df, use_container_width=True, hide_index=True)
        
        # Summary
        st.markdown("""
        <div style="background: #2c3e50; padding: 1rem; border-radius: 5px; margin-top: 1rem;">
            <p style="color: #2ecc71; margin: 0;"><strong>‚úÖ K·∫øt lu·∫≠n:</strong> M√¥ h√¨nh c√≥ ƒë·ªô ch√≠nh x√°c cao (92%) v·ªõi kh·∫£ nƒÉng ph√¢n lo·∫°i t·ªët cho c·∫£ hai class</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Row 7: Model Performance Summary
    st.markdown("---")
    col11, col12 = st.columns([1, 1])
    
    with col11:
        st.markdown("##### üìä Classification Report")
        
        # Classification Report - ƒë∆°n gi·∫£n h√≥a ƒë·ªÉ tr√°nh l·ªói hi·ªÉn th·ªã
        report_data = [
            ['Not Recommend', '0.97', '0.82', '0.89', '38'],
            ['Recommend', '0.89', '0.98', '0.93', '58'],
            ['Accuracy', '', '', '0.92', '96'],
            ['Macro avg', '0.93', '0.90', '0.91', '96'],
            ['Weighted avg', '0.92', '0.92', '0.92', '96']
        ]
        
        report_df = pd.DataFrame(report_data, columns=['Class', 'Precision', 'Recall', 'F1-score', 'Support'])
        
        # Hi·ªÉn th·ªã b·∫£ng ƒë∆°n gi·∫£n kh√¥ng c√≥ styling ph·ª©c t·∫°p
        st.dataframe(report_df, use_container_width=True, hide_index=True)
        
        # Summary
        st.markdown("""
        <div style="background: #2c3e50; padding: 1rem; border-radius: 5px; margin-top: 1rem;">
            <p style="color: #2ecc71; margin: 0;"><strong>‚úÖ K·∫øt lu·∫≠n:</strong> M√¥ h√¨nh c√≥ ƒë·ªô ch√≠nh x√°c cao (92%) v·ªõi kh·∫£ nƒÉng ph√¢n lo·∫°i t·ªët cho c·∫£ hai class</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col12:
        st.markdown("##### üìä Model Performance Summary")
        
        # Model performance summary - s·ª≠ d·ª•ng HTML ƒë·ªÉ tr√°nh nested columns
        st.info("üèÜ **Best Model: SKL_Gradient_Boosting**")
        
        # S·ª≠ d·ª•ng HTML/CSS ƒë·ªÉ hi·ªÉn th·ªã metrics theo h√†ng ngang
        st.markdown("""
        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; margin: 1rem 0;">
            <div style="background: #f0f2f6; padding: 1rem; border-radius: 5px; text-align: center;">
                <h4 style="margin: 0; color: #262730;">‚úÖ Accuracy</h4>
                <h2 style="margin: 0.5rem 0 0 0; color: #262730;">91.67%</h2>
            </div>
            <div style="background: #f0f2f6; padding: 1rem; border-radius: 5px; text-align: center;">
                <h4 style="margin: 0; color: #262730;">üéØ Precision</h4>
                <h2 style="margin: 0.5rem 0 0 0; color: #262730;">89.06%</h2>
            </div>
        </div>
        
        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; margin: 1rem 0;">
            <div style="background: #f0f2f6; padding: 1rem; border-radius: 5px; text-align: center;">
                <h4 style="margin: 0; color: #262730;">üìà Recall</h4>
                <h2 style="margin: 0.5rem 0 0 0; color: #262730;">98.28%</h2>
            </div>
            <div style="background: #f0f2f6; padding: 1rem; border-radius: 5px; text-align: center;">
                <h4 style="margin: 0; color: #262730;">üèÖ F1-Score</h4>
                <h2 style="margin: 0.5rem 0 0 0; color: #262730;">93.44%</h2>
            </div>
        </div>
        
        <div style="background: #ffd700; padding: 1rem; border-radius: 5px; text-align: center; margin: 1rem 0;">
            <h4 style="margin: 0; color: #000;">‚ö° ROC-AUC</h4>
            <h2 style="margin: 0.5rem 0 0 0; color: #000;">96.96%</h2>
        </div>
        """, unsafe_allow_html=True)
        
        # K·∫øt lu·∫≠n
        st.success("üí° **K·∫øt lu·∫≠n:** Gradient Boosting l√† m√¥ h√¨nh t·ªët nh·∫•t v·ªõi kh·∫£ nƒÉng d·ª± ƒëo√°n ch√≠nh x√°c v√† c√¢n b·∫±ng t·ªët gi·ªØa precision v√† recall.")

def show_candidate_search():
    """Hi·ªÉn th·ªã t√¨m ki·∫øm c√¥ng ty"""
    st.markdown("#### üîç T√¨m ki·∫øm c√¥ng ty")
    
    # Load data
    @st.cache_data
    def load_company_data():
        try:
            df = pd.read_csv("data/companies_with_recommend.csv")
            return df
        except FileNotFoundError:
            st.error("‚ùå Kh√¥ng t√¨m th·∫•y file data/companies_with_recommend.csv")
            return None
        except Exception as e:
            st.error(f"‚ùå L·ªói ƒë·ªçc file: {str(e)}")
            return None
    
    df = load_company_data()
    
    if df is None:
        return
    
    # Search interface
    col1, col2 = st.columns([3, 1])
    
    with col1:
        search_query = st.text_input(
            "üè¢ Nh·∫≠p t√™n c√¥ng ty:",
            placeholder="VD: FPT Software, VNG, Tiki...",
            help="Nh·∫≠p t√™n ƒë√∫ng ho·∫∑c g·∫ßn ƒë√∫ng"
        )
    
    with col2:
        search_button = st.button("üîç T√¨m ki·∫øm", type="primary", use_container_width=True)
    
    # Search results
    if search_query and (search_button or len(search_query) > 2):
        # Fuzzy search - t√¨m ki·∫øm g·∫ßn ƒë√∫ng
        mask = df['Company Name'].str.contains(search_query, case=False, na=False)
        results = df[mask]
        
        if len(results) == 0:
            st.warning(f"‚ùå Kh√¥ng t√¨m th·∫•y c√¥ng ty n√†o v·ªõi t·ª´ kh√≥a: '{search_query}'")
            
            # Suggest similar companies
            st.markdown("##### üí° G·ª£i √Ω m·ªôt s·ªë c√¥ng ty kh√°c:")
            sample_companies = df['Company Name'].sample(min(5, len(df))).tolist()
            for company in sample_companies:
                st.markdown(f"‚Ä¢ {company}")
        
        else:
            st.success(f"‚úÖ T√¨m th·∫•y {len(results)} c√¥ng ty")
            
            # Display results
            for idx, row in results.iterrows():
                recommend_status = "‚úÖ RECOMMEND" if row['recommend'] == 1 else "‚ùå NOT RECOMMEND"
                
                # Company header v·ªõi container
                with st.container():
                    col_name, col_status = st.columns([3, 1])
                    
                    with col_name:
                        st.markdown(f"### üè¢ {row['Company Name']}")
                    
                    with col_status:
                        if row['recommend'] == 1:
                            st.success(recommend_status)
                        else:
                            st.error(recommend_status)
                    
                    # Basic info trong 2 c·ªôt
                    col_info1, col_info2 = st.columns(2)
                    
                    with col_info1:
                        st.markdown(f"**üè¢ Lo·∫°i:** {row['Company Type']}")
                        st.markdown(f"**üè≠ Ng√†nh:** {row['Company industry']}")
                        st.markdown(f"**üë• Quy m√¥:** {row['Company size']}")
                    
                    with col_info2:
                        st.markdown(f"**üåç Qu·ªëc gia:** {row['Country']}")
                        st.markdown(f"**üìÖ Ng√†y l√†m:** {row['Working days']}")
                        st.markdown(f"**‚è∞ OT Policy:** {row['Overtime Policy']}")
                    
                    st.markdown(f"**üìç ƒê·ªãa ƒëi·ªÉm:** {row['Location']}")
                
                # Expandable details
                with st.expander(f"üìã Chi ti·∫øt {row['Company Name']}", expanded=False):
                    
                    col_detail1, col_detail2 = st.columns(2)
                    
                    with col_detail1:
                        st.markdown("**üè¢ T·ªïng quan c√¥ng ty:**")
                        overview = row['Company overview'] if pd.notna(row['Company overview']) else "Kh√¥ng c√≥ th√¥ng tin"
                        st.write(overview)
                        
                        st.markdown("**üîß K·ªπ nƒÉng ch√≠nh:**")
                        skills = row['Our key skills'] if pd.notna(row['Our key skills']) else "Kh√¥ng c√≥ th√¥ng tin"
                        st.write(skills)
                    
                    with col_detail2:
                        st.markdown("**‚ù§Ô∏è T·∫°i sao b·∫°n s·∫Ω th√≠ch l√†m vi·ªác ·ªü ƒë√¢y:**")
                        why_love = row['Why you\'ll love working here'] if pd.notna(row['Why you\'ll love working here']) else "Kh√¥ng c√≥ th√¥ng tin"
                        st.write(why_love)
                        
                        # Text statistics
                        st.markdown("**üìä Th·ªëng k√™ vƒÉn b·∫£n:**")
                        st.metric("ƒê·ªô d√†i vƒÉn b·∫£n", f"{row['text_length']} k√Ω t·ª±")
                        st.metric("S·ªë t·ª´", f"{row['word_count']} t·ª´")
                    
                    # Company link
                    if pd.notna(row['Href']) and row['Href'].startswith('http'):
                        st.markdown(f"üîó [Xem chi ti·∫øt tr√™n ITViec]({row['Href']})")
                
                st.divider()
    
    # Statistics panel
    if df is not None:
        st.markdown("### üìä Th·ªëng k√™ t·ªïng quan")
        
        col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
        
        with col_stat1:
            st.metric("üè¢ T·ªïng s·ªë c√¥ng ty", len(df))
        
        with col_stat2:
            recommend_count = len(df[df['recommend'] == 1])
            st.metric("‚úÖ ƒê∆∞·ª£c recommend", f"{recommend_count} ({recommend_count/len(df)*100:.1f}%)")
        
        with col_stat3:
            not_recommend_count = len(df[df['recommend'] == 0])
            st.metric("‚ùå Kh√¥ng recommend", f"{not_recommend_count} ({not_recommend_count/len(df)*100:.1f}%)")
        
        with col_stat4:
            avg_text_length = df['text_length'].mean()
            st.metric("üìù ƒê·ªô d√†i TB", f"{avg_text_length:.0f} k√Ω t·ª±")

def show_candidate_predict():
    """Hi·ªÉn th·ªã d·ª± ƒëo√°n b·∫±ng m√¥ h√¨nh"""
    st.markdown("#### ü§ñ D·ª± ƒëo√°n b·∫±ng m√¥ h√¨nh AI")
    st.markdown("Nh·∫≠p th√¥ng tin c√¥ng ty ƒë·ªÉ d·ª± ƒëo√°n kh·∫£ nƒÉng **Recommend** hay **Not Recommend**")
    
    # Load model and existing preprocessing components
    @st.cache_resource
    def load_model_and_preprocessors():
        """Load model v√† c√°c preprocessing components c√≥ s·∫µn"""
        
        try:
            # Load main model
            model = joblib.load("model/best_model_skl_gradient_boosting.pkl")
            # st.success("‚úÖ Loaded best_model_skl_gradient_boosting.pkl")
            
            # Load label encoders  
            label_encoders = joblib.load("model/label_encoders.pkl")
            # st.success("‚úÖ Loaded label_encoders.pkl")
            
            # Load feature scaler
            feature_scaler = joblib.load("model/feature_scaler.pkl") 
            # st.success("‚úÖ Loaded feature_scaler.pkl")
            
            # Try to load text embeddings if available
            text_embeddings = None
            try:
                text_embeddings = np.load("files/text_embeddings.npy")
                # st.success("‚úÖ Loaded text_embeddings.npy")
            except:
                st.info("‚ÑπÔ∏è text_embeddings.npy not found - will use simplified approach")
            
            return {
                'model': model,
                'label_encoders': label_encoders, 
                'feature_scaler': feature_scaler,
                'text_embeddings': text_embeddings,
                'status': 'real'
            }
            
        except FileNotFoundError as e:
            st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {str(e)}")
            st.error("üí° Vui l√≤ng ƒë·∫£m b·∫£o c√°c file model ƒë√£ ƒë∆∞·ª£c l∆∞u ƒë√∫ng ƒë∆∞·ªùng d·∫´n")
            return None
        except Exception as e:
            st.error(f"‚ùå L·ªói load files: {str(e)}")
            return None
    
    # Load reference data
    @st.cache_data
    def load_reference_data():
        try:
            df = pd.read_csv("data/companies_with_recommend.csv")
            return df
        except:
            return None
    
    components = load_model_and_preprocessors()
    if components is None:
        st.error("‚ùå Kh√¥ng th·ªÉ load model. Vui l√≤ng ki·ªÉm tra l·∫°i c√°c file:")
        st.code("""
        model/best_model_skl_gradient_boosting.pkl
        model/label_encoders.pkl  
        model/feature_scaler.pkl
        files/text_embeddings.npy (optional)
        """)
        return
    
    model = components['model']
    label_encoders = components['label_encoders']
    feature_scaler = components['feature_scaler']
    text_embeddings = components['text_embeddings']
    
    ref_df = load_reference_data()
    
    # Hi·ªÉn th·ªã th√¥ng tin model
    # st.info("ü§ñ S·ª≠ d·ª•ng Model th·∫≠t v·ªõi preprocessing components c√≥ s·∫µn")
    if hasattr(model, 'n_features_in_'):
        # st.info(f"üìä Model expects {model.n_features_in_} features")
        pass
    
    # Input form
    st.markdown("### üìù Nh·∫≠p th√¥ng tin c√¥ng ty")
    
    # Column 1: Basic info
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üè¢ Th√¥ng tin c∆° b·∫£n")
        
        # Company Type
        company_types = ['IT Product', 'IT Outsourcing', 'IT Service and IT Consulting', 'Non-IT']
        if ref_df is not None:
            company_types = ref_df['Company Type'].unique().tolist()
        
        company_type = st.selectbox(
            "üè¢ Lo·∫°i c√¥ng ty:",
            options=company_types,
            index=0
        )
        
        # Company Industry
        industries = ['Software Products and Web Services', 'IT Services and IT Consulting', 
                     'Software Development Outsourcing', 'Financial Services', 'E-commerce']
        if ref_df is not None:
            industries = ref_df['Company industry'].unique().tolist()
        
        company_industry = st.selectbox(
            "üè≠ Ng√†nh ngh·ªÅ:",
            options=industries,
            index=0
        )
        
        # Company Size
        sizes = ['1-50 employees', '51-150 employees', '151-300 employees', 
                '301-500 employees', '501-1000 employees', '1000+ employees']
        if ref_df is not None:
            sizes = ref_df['Company size'].unique().tolist()
        
        company_size = st.selectbox(
            "üë• Quy m√¥:",
            options=sizes,
            index=0
        )
    
    with col2:
        st.markdown("#### ‚öôÔ∏è Ch√≠nh s√°ch l√†m vi·ªác")
        
        # Overtime Policy
        ot_policies = ['No OT', 'Extra salary for OT', 'Extra days off for OT', 'OT included in base salary']
        if ref_df is not None:
            ot_policies = ref_df['Overtime Policy'].unique().tolist()
        
        overtime_policy = st.selectbox(
            "‚è∞ Ch√≠nh s√°ch OT:",
            options=ot_policies,
            index=0
        )
        
        # Location (ch·ªâ ƒë·ªÉ hi·ªÉn th·ªã, kh√¥ng d√πng cho prediction)
        location = st.text_input(
            "üìç ƒê·ªãa ƒëi·ªÉm:",
            placeholder="VD: Ho Chi Minh City, Ha Noi...",
            value="Ho Chi Minh City",
            help="Ch·ªâ ƒë·ªÉ hi·ªÉn th·ªã, kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn d·ª± ƒëo√°n"
        )
    
    # Text inputs
    st.markdown("#### üìù M√¥ t·∫£ c√¥ng ty")
    
    col3, col4 = st.columns(2)
    
    with col3:
        company_overview = st.text_area(
            "üè¢ T·ªïng quan c√¥ng ty:",
            placeholder="M√¥ t·∫£ ng·∫Øn v·ªÅ c√¥ng ty...",
            height=100
        )
        
        our_key_skills = st.text_area(
            "üîß K·ªπ nƒÉng ch√≠nh:",
            placeholder="C√°c k·ªπ nƒÉng v√† c√¥ng ngh·ªá ch√≠nh...",
            height=100
        )
    
    with col4:
        why_love_working = st.text_area(
            "‚ù§Ô∏è T·∫°i sao b·∫°n s·∫Ω th√≠ch l√†m vi·ªác ·ªü ƒë√¢y:",
            placeholder="L√Ω do ·ª©ng vi√™n n√™n ch·ªçn c√¥ng ty...",
            height=100
        )
        
        # Combined text s·∫Ω ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông
        st.info("üí° VƒÉn b·∫£n t·ªïng h·ª£p s·∫Ω ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông t·ª´ c√°c m√¥ t·∫£ tr√™n")
    
    # Predict button
    col_predict1, col_predict2, col_predict3 = st.columns([1, 1, 1])
    
    with col_predict2:
        predict_button = st.button(
            "üöÄ D·ª± ƒëo√°n", 
            type="primary", 
            use_container_width=True,
            help="Click ƒë·ªÉ d·ª± ƒëo√°n Recommend/Not Recommend"
        )
    
    # Prediction logic
    if predict_button:
        if not all([company_overview, our_key_skills, why_love_working]):
            st.warning("‚ö†Ô∏è Vui l√≤ng ƒëi·ªÅn ƒë·∫ßy ƒë·ªß th√¥ng tin m√¥ t·∫£ c√¥ng ty!")
            return
        
        try:
            # Use real model with existing preprocessing components
            # st.info("üîÑ ƒêang x·ª≠ l√Ω v·ªõi preprocessing components c√≥ s·∫µn...")
            
            # Prepare text data
            combined_text = f"{company_overview} {our_key_skills} {why_love_working}"
            text_length = len(combined_text)
            word_count = len(combined_text.split())
            
            # FIXED: S·ª≠ d·ª•ng ƒë√∫ng 4 features nh∆∞ training
            categorical_columns = ['Company Type', 'Company industry', 'Company size', 'Overtime Policy']
            input_values = [company_type, company_industry, company_size, overtime_policy]
            
            # Process categorical features using existing label encoders
            categorical_data = []
            
            for col, value in zip(categorical_columns, input_values):
                if col in label_encoders:
                    le = label_encoders[col]
                    # Handle unknown values
                    if value in le.classes_:
                        encoded_val = le.transform([value])[0]
                    else:
                        # Use most frequent class as fallback
                        encoded_val = 0
                        st.warning(f"‚ö†Ô∏è Unknown value '{value}' for '{col}', using fallback")
                    categorical_data.append(encoded_val)
                else:
                    categorical_data.append(0)
                    st.warning(f"‚ö†Ô∏è No encoder for '{col}', using fallback")
            
            # st.success(f"‚úÖ Prepared {len(categorical_data)} categorical features for scaler")
            
            # Scale categorical features using existing scaler
            categorical_array = np.array(categorical_data).reshape(1, -1)
            categorical_scaled = feature_scaler.transform(categorical_array)[0]
            # st.success(f"‚úÖ Successfully scaled features to shape: {categorical_scaled.shape}")
            
            # Handle text embeddings
            if text_embeddings is not None:
                # Use pre-computed embeddings (for demo, use first embedding)
                # st.info("üìù S·ª≠ d·ª•ng pre-computed text embeddings")
                text_features = text_embeddings[0]  
            else:
                # Create dummy text embeddings for demo
                st.warning("‚ö†Ô∏è T·∫°o dummy text embeddings cho demo")
                text_features = np.random.normal(0, 0.1, 768)
            
            # Combine all features to match model input
            X = np.concatenate([text_features, categorical_scaled]).reshape(1, -1)
            
            # st.success(f"‚úÖ ƒê√£ t·∫°o {X.shape[1]} features ƒë·ªÉ input v√†o model")
            
            # Make prediction
            prediction = model.predict(X)[0]
            prediction_proba = model.predict_proba(X)[0]
            
            # Display results
            st.markdown("---")
            st.markdown("### üéØ K·∫øt qu·∫£ d·ª± ƒëo√°n")
            
            col_result1, col_result2, col_result3 = st.columns([1, 2, 1])
            
            with col_result2:
                if prediction == 1:
                    st.success("### ‚úÖ RECOMMEND")
                    st.balloons()
                else:
                    st.error("### ‚ùå NOT RECOMMEND")
                
                # Probability display
                recommend_prob = prediction_proba[1] * 100
                not_recommend_prob = prediction_proba[0] * 100
                
                st.markdown("#### üìä X√°c su·∫•t d·ª± ƒëo√°n:")
                
                st.markdown(f"**‚úÖ Recommend:** {recommend_prob:.1f}%")
                st.progress(recommend_prob / 100)
                
                st.markdown(f"**‚ùå Not Recommend:** {not_recommend_prob:.1f}%")
                st.progress(not_recommend_prob / 100)
                
                # Confidence level
                confidence = max(recommend_prob, not_recommend_prob)
                if confidence >= 80:
                    st.success(f"üéØ ƒê·ªô tin c·∫≠y cao: {confidence:.1f}%")
                elif confidence >= 60:
                    st.warning(f"‚ö†Ô∏è ƒê·ªô tin c·∫≠y trung b√¨nh: {confidence:.1f}%")
                else:
                    st.error(f"‚ùå ƒê·ªô tin c·∫≠y th·∫•p: {confidence:.1f}%")
            
            # Feature importance visualization
            # if hasattr(model, 'feature_importances_'):
            #     st.markdown("### üìà T·∫ßm quan tr·ªçng c·ªßa c√°c y·∫øu t·ªë")
                
            #     # Create meaningful feature names  
            #     text_features_names = [f'text_dim_{i}' for i in range(768)]
            #     cat_features_names = ['Company_Type', 'Company_Industry', 'Company_Size', 'Overtime_Policy']
            #     all_feature_names = text_features_names + cat_features_names
                
            #     # Get top important features
            #     feature_importance_data = list(zip(all_feature_names, model.feature_importances_))
            #     feature_importance_data.sort(key=lambda x: x[1], reverse=True)
                
            #     # Show top 20
            #     top_features = feature_importance_data[:20]
                
            #     importance_df = pd.DataFrame(top_features, columns=['feature', 'importance'])
                
            #     fig = go.Figure(go.Bar(
            #         x=importance_df['importance'],
            #         y=importance_df['feature'],
            #         orientation='h',
            #         marker_color='lightblue'
            #     ))
                
            #     fig.update_layout(
            #         title="Top 20 Features quan tr·ªçng nh·∫•t",
            #         xaxis_title="T·∫ßm quan tr·ªçng",
            #         yaxis_title="Features",
            #         height=600,
            #         plot_bgcolor='rgba(0,0,0,0)',
            #         paper_bgcolor='rgba(0,0,0,0)',
            #         font_color='white'
            #     )
                
            #     st.plotly_chart(fig, use_container_width=True)
            
            # Summary information
            st.markdown("### üìã T√≥m t·∫Øt th√¥ng tin")
            
            col_summary1, col_summary2 = st.columns(2)
            
            with col_summary1:
                st.markdown("**üè¢ Th√¥ng tin c√¥ng ty:**")
                st.write(f"‚Ä¢ Lo·∫°i: {company_type}")
                st.write(f"‚Ä¢ Ng√†nh: {company_industry}")
                st.write(f"‚Ä¢ Quy m√¥: {company_size}")
                st.write(f"‚Ä¢ Ch√≠nh s√°ch OT: {overtime_policy}")
            
            with col_summary2:
                st.markdown("**üìä Th·ªëng k√™:**")
                st.write(f"‚Ä¢ ƒê·ªô d√†i vƒÉn b·∫£n: {text_length} k√Ω t·ª±")
                st.write(f"‚Ä¢ S·ªë t·ª´: {word_count} t·ª´")
                st.write(f"‚Ä¢ Features ƒë∆∞·ª£c t·∫°o: {X.shape[1]}")
                st.write(f"‚Ä¢ ƒê·ªãa ƒëi·ªÉm: {location}")
        
        except Exception as e:
            st.error(f"‚ùå L·ªói trong qu√° tr√¨nh d·ª± ƒëo√°n: {str(e)}")
            st.error("üí° Vui l√≤ng ki·ªÉm tra l·∫°i d·ªØ li·ªáu ƒë·∫ßu v√†o v√† model")
            
            # Show detailed error for debugging
            with st.expander("üîç Chi ti·∫øt l·ªói", expanded=False):
                st.code(str(e))
                import traceback
                st.code(traceback.format_exc())
    
    # # Instructions
    # with st.expander("üìñ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng", expanded=False):
    #     st.markdown("""
    #     ### üéØ C√°ch s·ª≠ d·ª•ng:
    #     1. **ƒêi·ªÅn th√¥ng tin c∆° b·∫£n** v·ªÅ c√¥ng ty (lo·∫°i, ng√†nh, quy m√¥, OT policy)
    #     2. **M√¥ t·∫£ chi ti·∫øt** v·ªÅ c√¥ng ty trong 3 √¥ text
    #     3. **Click D·ª± ƒëo√°n** ƒë·ªÉ nh·∫≠n k·∫øt qu·∫£
        
    #     ### üìä K·∫øt qu·∫£ bao g·ªìm:
    #     - **D·ª± ƒëo√°n ch√≠nh**: Recommend hay Not Recommend
    #     - **X√°c su·∫•t**: T·ª∑ l·ªá % cho m·ªói class
    #     - **ƒê·ªô tin c·∫≠y**: M·ª©c ƒë·ªô ch·∫Øc ch·∫Øn c·ªßa model
    #     - **Feature Importance**: Y·∫øu t·ªë n√†o quan tr·ªçng nh·∫•t
        
    #     ### ü§ñ Model Information:
    #     - **Model**: GradientBoostingClassifier t·ª´ Scikit-learn
    #     - **Features**: 4 categorical + 768 text embeddings = 772 total
    #     - **Files c·∫ßn thi·∫øt**: 
    #       - `model/best_model_skl_gradient_boosting.pkl`
    #       - `model/label_encoders.pkl`
    #       - `model/feature_scaler.pkl`
    #       - `files/text_embeddings.npy` (optional)
        
    #     ### üí° L∆∞u √Ω:
    #     - Model ƒë∆∞·ª£c train tr√™n d·ªØ li·ªáu ITViec th·∫≠t
    #     - Ch·ªâ s·ª≠ d·ª•ng 4 categorical features nh∆∞ training
    #     - Text embeddings: S·ª≠ d·ª•ng pre-computed n·∫øu c√≥, dummy n·∫øu kh√¥ng
    #     - K·∫øt qu·∫£ ph·ª• thu·ªôc v√†o ch·∫•t l∆∞·ª£ng m√¥ t·∫£ c√¥ng ty
    #     """)
    
    # # Technical info
    # with st.expander("üî¨ Th√¥ng tin k·ªπ thu·∫≠t", expanded=False):
    #     st.markdown("#### üß† Architecture:")
    #     st.markdown("""
    #     **Preprocessing Pipeline:**
    #     - Categorical encoding: Label encoders t·ª´ training (4 features)
    #     - Feature scaling: StandardScaler t·ª´ training  
    #     - Text processing: Pre-computed embeddings ho·∫∑c dummy cho demo
        
    #     **Model Details:**
    #     - Type: GradientBoostingClassifier (Scikit-learn)
    #     - Features: 772 total (768 text + 4 categorical scaled)
    #     - Training: ƒê√£ ho√†n th√†nh v·ªõi d·ªØ li·ªáu ITViec
        
    #     **Categorical Features Used:**
    #     - Company Type
    #     - Company industry  
    #     - Company size
    #     - Overtime Policy
        
    #     **Files Usage:**
    #     - Model: Loaded t·ª´ best_model_skl_gradient_boosting.pkl
    #     - Encoders: Loaded t·ª´ label_encoders.pkl
    #     - Scaler: Loaded t·ª´ feature_scaler.pkl
    #     - Embeddings: Optional t·ª´ text_embeddings.npy
    #     """)
        
    #     st.markdown("#### üìä Current Model Stats:")
    #     if hasattr(model, 'n_features_in_'):
    #         st.write(f"‚Ä¢ Expected features: {model.n_features_in_}")
    #     if hasattr(model, 'n_classes_'):
    #         st.write(f"‚Ä¢ Number of classes: {model.n_classes_}")
    #     if hasattr(model, 'feature_importances_'):
    #         st.write(f"‚Ä¢ Feature importance available: ‚úÖ")
            
    #         # Show categorical feature importance
    #         if label_encoders:
    #             cat_start_idx = 768  # After text features
    #             cat_importance = model.feature_importances_[cat_start_idx:]
    #             cat_names = ['Company_Type', 'Company_Industry', 'Company_Size', 'Overtime_Policy']
                
    #             st.write("‚Ä¢ Categorical features importance:")
    #             for i, (name, imp) in enumerate(zip(cat_names, cat_importance)):
    #                 st.write(f"  {i+1}. {name}: {imp:.4f}")
        
    #     # Show loaded components info
    #     st.markdown("#### üì¶ Loaded Components:")
    #     st.write(f"‚Ä¢ Label encoders: {len(label_encoders) if label_encoders else 0} columns")
    #     st.write(f"‚Ä¢ Feature scaler: {'‚úÖ' if feature_scaler else '‚ùå'}")
    #     st.write(f"‚Ä¢ Text embeddings: {'‚úÖ' if text_embeddings is not None else '‚ùå (using dummy)'}")
        
    #     if label_encoders:
    #         st.write("‚Ä¢ Categorical columns:")
    #         for col, encoder in label_encoders.items():
    #             st.write(f"  - {col}: {len(encoder.classes_)} classes")

def candidate_classification_tab():
    """Main function cho Candidate Classification tab"""
    st.markdown("## üë§ Candidate Classification")
    
    # Sidebar cho Candidate Classification
    col1, col2 = st.columns([1, 4])
    
    with col1:
        st.markdown("""
        <div style="background: #2c3e50; padding: 1rem; border-radius: 10px; margin-bottom: 1rem;">
            <h4 style="color: white; text-align: center; margin-bottom: 1rem;">üìã Menu</h4>
        </div>
        """, unsafe_allow_html=True)
        
        # Navigation buttons
        if st.button("üìä T·ªïng quan", key="overview", use_container_width=True):
            st.session_state.candidate_page = "overview"
        
        if st.button("üîç T√¨m ki·∫øm c√¥ng ty", key="search", use_container_width=True):
            st.session_state.candidate_page = "search"
            
        if st.button("ü§ñ D·ª± ƒëo√°n b·∫±ng m√¥ h√¨nh", key="predict", use_container_width=True):
            st.session_state.candidate_page = "predict"
    
    with col2:
        # Initialize session state
        if 'candidate_page' not in st.session_state:
            st.session_state.candidate_page = "overview"
        
        # Content area based on selected page
        if st.session_state.candidate_page == "overview":
            show_candidate_overview()
        elif st.session_state.candidate_page == "search":
            show_candidate_search()
        elif st.session_state.candidate_page == "predict":
            show_candidate_predict()